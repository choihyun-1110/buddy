"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ ëª¨ë“œë¡œ íŠ¹ì • ì´ë¯¸ì§€ ì¶”ë¡  ë° ì‹œê°í™”
"""
import cv2
import numpy as np
import onnxruntime as ort
from pathlib import Path
import time
from typing import List, Tuple

# ONNX ëª¨ë¸ ê²½ë¡œ
ONNX_MODEL = "results/training_20251031_201041/best_model.onnx"
IMAGE_PATH = "dataset_augmented_v3/test/images/29002_0004_aug_0001.png"
OUTPUT_DIR = Path("results/visualizations")
OUTPUT_DIR.mkdir(exist_ok=True)

# í´ë˜ìŠ¤ ì´ë¦„
CLASS_NAMES = [
    "29002", "34342", "37990", "39916", "40122", "40720", "40767", "40792",
    "40837", "40949", "40953", "40990", "40991", "41097", "41107", "41169",
    "41170", "41172", "41207", "41225", "41327", "41344"
]

def load_onnx_model(onnx_path: str):
    """ONNX ëª¨ë¸ ë¡œë“œ (CPU ì „ìš©)"""
    sess_options = ort.SessionOptions()
    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
    
    # ë¼ì¦ˆë² ë¦¬íŒŒì´ ëª¨ë“œ: CPUë§Œ ì‚¬ìš©
    providers = ['CPUExecutionProvider']
    
    session = ort.InferenceSession(
        str(onnx_path),
        sess_options=sess_options,
        providers=providers
    )
    
    input_name = session.get_inputs()[0].name
    input_shape = session.get_inputs()[0].shape
    input_size = (input_shape[2], input_shape[3])  # (width, height)
    
    print(f"âœ… ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (CPU ëª¨ë“œ)")
    print(f"   ì…ë ¥ í¬ê¸°: {input_size}")
    
    return session, input_name, input_size

def preprocess_image(image_path: str, target_size: tuple) -> np.ndarray:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    img = cv2.imread(str(image_path))
    if img is None:
        raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
    
    original_shape = img.shape[:2]
    
    # ë¦¬ì‚¬ì´ì¦ˆ
    img_resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)
    
    # BGR -> RGB
    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    
    # ì •ê·œí™” (0-255 -> 0-1)
    img_normalized = img_rgb.astype(np.float32) / 255.0
    
    # (H, W, C) -> (C, H, W)
    img_transposed = img_normalized.transpose(2, 0, 1)
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, C, H, W)
    img_batch = np.expand_dims(img_transposed, axis=0)
    
    return img_batch, original_shape

def postprocess_yolo_output(outputs: list, conf_threshold: float = 0.25, num_classes: int = 22) -> list:
    """YOLO ì¶œë ¥ í›„ì²˜ë¦¬ (YOLOv8 í˜•ì‹)"""
    detections = []
    
    if len(outputs) > 0:
        output = outputs[0]  # [batch, num_features, num_anchors]
        
        if output.ndim == 3:
            output = output[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°: [num_features, num_anchors]
        
        # YOLOv8 ì¶œë ¥ í˜•ì‹: [batch, num_features, num_anchors]
        # num_features = 4 (bbox) + num_classes
        # ì¶œë ¥ì„ transpose: [num_anchors, num_features]
        if output.ndim == 2:
            output = output.transpose(1, 0)  # [num_anchors, num_features]
        
        # ë°•ìŠ¤ ì¢Œí‘œì™€ í´ë˜ìŠ¤ í™•ë¥  ë¶„ë¦¬
        boxes = output[:, :4]  # [num_anchors, 4] - ì •ê·œí™”ëœ xywh
        scores = output[:, 4:]  # [num_anchors, num_classes] - í´ë˜ìŠ¤ í™•ë¥ 
        
        # ê° ì•µì»¤ì— ëŒ€í•´ ìµœëŒ€ í´ë˜ìŠ¤ í™•ë¥ ê³¼ í´ë˜ìŠ¤ ID ì°¾ê¸°
        max_scores = np.max(scores, axis=1)  # [num_anchors]
        class_ids = np.argmax(scores, axis=1)  # [num_anchors]
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ í•„í„°ë§
        valid_indices = max_scores > conf_threshold
        
        if np.any(valid_indices):
            valid_boxes = boxes[valid_indices]
            valid_scores = max_scores[valid_indices]
            valid_class_ids = class_ids[valid_indices]
            
            for box, score, class_id in zip(valid_boxes, valid_scores, valid_class_ids):
                x_center, y_center, width, height = box
                
                detections.append({
                    'bbox': [float(x_center), float(y_center), float(width), float(height)],
                    'confidence': float(score),
                    'class_id': int(class_id)
                })
    
    return detections

def nms(boxes: np.ndarray, scores: np.ndarray, iou_threshold: float = 0.45) -> np.ndarray:
    """Non-Maximum Suppression"""
    if len(boxes) == 0:
        return np.array([])
    
    # xywhë¥¼ xyxyë¡œ ë³€í™˜
    x_center, y_center, width, height = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    x1 = x_center - width / 2
    y1 = y_center - height / 2
    x2 = x_center + width / 2
    y2 = y_center + height / 2
    
    boxes_xyxy = np.column_stack([x1, y1, x2, y2])
    
    # ë©´ì  ê³„ì‚°
    areas = (x2 - x1) * (y2 - y1)
    
    # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ì¸ë±ìŠ¤
    order = scores.argsort()[::-1]
    
    keep = []
    while len(order) > 0:
        i = order[0]
        keep.append(i)
        
        if len(order) == 1:
            break
        
        # IoU ê³„ì‚°
        xx1 = np.maximum(boxes_xyxy[i, 0], boxes_xyxy[order[1:], 0])
        yy1 = np.maximum(boxes_xyxy[i, 1], boxes_xyxy[order[1:], 1])
        xx2 = np.minimum(boxes_xyxy[i, 2], boxes_xyxy[order[1:], 2])
        yy2 = np.minimum(boxes_xyxy[i, 3], boxes_xyxy[order[1:], 3])
        
        w = np.maximum(0, xx2 - xx1)
        h = np.maximum(0, yy2 - yy1)
        intersection = w * h
        
        union = areas[i] + areas[order[1:]] - intersection
        iou = intersection / union
        
        # IoU ì„ê³„ê°’ ì´í•˜ì¸ ë°•ìŠ¤ë§Œ ìœ ì§€
        order = order[1:][iou <= iou_threshold]
    
    return np.array(keep)

def postprocess_yolo_output_with_nms(outputs: list, conf_threshold: float = 0.25, 
                                     iou_threshold: float = 0.45, num_classes: int = 22) -> list:
    """YOLO ì¶œë ¥ í›„ì²˜ë¦¬ (NMS í¬í•¨)"""
    detections = []
    
    if len(outputs) > 0:
        output = outputs[0]  # [batch, num_features, num_anchors]
        
        if output.ndim == 3:
            output = output[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°: [num_features, num_anchors]
        
        # YOLOv8 ì¶œë ¥ í˜•ì‹: [batch, num_features, num_anchors]
        # num_features = 4 (bbox) + num_classes
        # ì¶œë ¥ì„ transpose: [num_anchors, num_features]
        if output.ndim == 2:
            output = output.transpose(1, 0)  # [num_anchors, num_features]
        
        # ë°•ìŠ¤ ì¢Œí‘œì™€ í´ë˜ìŠ¤ í™•ë¥  ë¶„ë¦¬
        boxes = output[:, :4]  # [num_anchors, 4] - ì •ê·œí™”ëœ xywh
        scores = output[:, 4:]  # [num_anchors, num_classes] - í´ë˜ìŠ¤ í™•ë¥ 
        
        # ê° ì•µì»¤ì— ëŒ€í•´ ìµœëŒ€ í´ë˜ìŠ¤ í™•ë¥ ê³¼ í´ë˜ìŠ¤ ID ì°¾ê¸°
        max_scores = np.max(scores, axis=1)  # [num_anchors]
        class_ids = np.argmax(scores, axis=1)  # [num_anchors]
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ í•„í„°ë§
        valid_indices = max_scores > conf_threshold
        
        if np.any(valid_indices):
            valid_boxes = boxes[valid_indices]
            valid_scores = max_scores[valid_indices]
            valid_class_ids = class_ids[valid_indices]
            
            # NMS ì ìš©
            nms_indices = nms(valid_boxes, valid_scores, iou_threshold)
            
            for idx in nms_indices:
                box = valid_boxes[idx]
                score = valid_scores[idx]
                class_id = valid_class_ids[idx]
                
                x_center, y_center, width, height = box
                
                detections.append({
                    'bbox': [float(x_center), float(y_center), float(width), float(height)],
                    'confidence': float(score),
                    'class_id': int(class_id)
                })
    
    return detections

def draw_detections(image_path: str, detections: list, output_path: str, original_shape: tuple, input_size: tuple):
    """ê°ì§€ ê²°ê³¼ ì‹œê°í™”"""
    img = cv2.imread(str(image_path))
    if img is None:
        return
    
    orig_h, orig_w = original_shape
    input_w, input_h = input_size  # input_sizeëŠ” (width, height) í˜•ì‹
    
    # ìŠ¤ì¼€ì¼ ë¹„ìœ¨ ê³„ì‚°
    scale_x = orig_w / input_w
    scale_y = orig_h / input_h
    
    # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ (ë””ë²„ê¹…ìš©, í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
    # print(f"\nğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´:")
    # print(f"   ì›ë³¸ í¬ê¸°: {orig_w}x{orig_h}")
    # print(f"   ì…ë ¥ í¬ê¸°: {input_w}x{input_h}")
    # print(f"   ìŠ¤ì¼€ì¼ ë¹„ìœ¨: {scale_x:.3f} x {scale_y:.3f}")
    
    for det in detections:
        x_center, y_center, width, height = det['bbox']
        conf = det['confidence']
        class_id = det['class_id']
        
        # YOLO ì¶œë ¥ ì¢Œí‘œ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
        # ë§Œì•½ ì´ë¯¸ í”½ì…€ ì¢Œí‘œë¼ë©´ (ê°’ì´ 1ë³´ë‹¤ í¬ë©´)
        if x_center > 1.0 or y_center > 1.0 or width > 1.0 or height > 1.0:
            # ì´ë¯¸ í”½ì…€ ì¢Œí‘œ (640x640 ê¸°ì¤€)
            x_center_px = x_center
            y_center_px = y_center
            width_px = width
            height_px = height
        else:
            # ì •ê·œí™”ëœ ì¢Œí‘œ (0-1)
            x_center_px = x_center * input_w
            y_center_px = y_center * input_h
            width_px = width * input_w
            height_px = height * input_h
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ìŠ¤ì¼€ì¼ë§ (ì´ë¯¸ì§€ê°€ 640x640ì´ë©´ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)
        if orig_w == input_w and orig_h == input_h:
            # ì´ë¯¸ì§€ í¬ê¸°ê°€ ê°™ìœ¼ë©´ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”
            x_center_scaled = x_center_px
            y_center_scaled = y_center_px
            width_scaled = width_px
            height_scaled = height_px
        else:
            # ë‹¤ë¥¸ í¬ê¸°ë©´ ìŠ¤ì¼€ì¼ë§ í•„ìš”
            x_center_scaled = x_center_px * scale_x
            y_center_scaled = y_center_px * scale_y
            width_scaled = width_px * scale_x
            height_scaled = height_px * scale_y
        
        # xywhë¥¼ xyxyë¡œ ë³€í™˜
        x1 = int(x_center_scaled - width_scaled / 2)
        y1 = int(y_center_scaled - height_scaled / 2)
        x2 = int(x_center_scaled + width_scaled / 2)
        y2 = int(y_center_scaled + height_scaled / 2)
        
        # ì¢Œí‘œ ë²”ìœ„ ì œí•œ
        x1 = max(0, min(x1, orig_w - 1))
        y1 = max(0, min(y1, orig_h - 1))
        x2 = max(0, min(x2, orig_w - 1))
        y2 = max(0, min(y2, orig_h - 1))
        
        # ì¢Œí‘œ ìœ íš¨ì„± í™•ì¸
        if x2 <= x1 or y2 <= y1:
            print(f"   âš ï¸ ì˜ëª»ëœ ë°•ìŠ¤ ì¢Œí‘œ: ({x1}, {y1}) -> ({x2}, {y2}), ê±´ë„ˆëœ€")
            continue
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì„  ë‘ê»˜ë¥¼ ë” ë‘ê»ê²Œ)
        color = (0, 255, 0)  # ì´ˆë¡ìƒ‰ (BGR)
        thickness = 3  # ì„  ë‘ê»˜
        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)
        
        # ë¼ë²¨ ê·¸ë¦¬ê¸°
        class_name = CLASS_NAMES[class_id] if class_id < len(CLASS_NAMES) else f"class_{class_id}"
        label = f"{class_name}: {conf:.2f}"
        
        # í…ìŠ¤íŠ¸ ë°°ê²½
        (label_width, label_height), baseline = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2
        )
        cv2.rectangle(
            img, 
            (x1, y1 - label_height - baseline - 5),
            (x1 + label_width, y1),
            color,
            -1
        )
        
        # í…ìŠ¤íŠ¸
        cv2.putText(
            img, 
            label, 
            (x1, y1 - baseline - 5),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            (0, 0, 0),
            2
        )
    
    cv2.imwrite(str(output_path), img)
    print(f"âœ… ê²°ê³¼ ì €ì¥: {output_path}")

def main():
    print("="*60)
    print("ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ ëª¨ë“œ ì¶”ë¡  ë° ì‹œê°í™”")
    print("="*60)
    
    # ëª¨ë¸ ë¡œë“œ
    session, input_name, input_size = load_onnx_model(ONNX_MODEL)
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    image_path = Path(IMAGE_PATH)
    if not image_path.exists():
        print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return
    
    print(f"\nğŸ“¸ ì´ë¯¸ì§€ ë¡œë“œ: {image_path.name}")
    img_batch, original_shape = preprocess_image(str(image_path), input_size)
    
    # ì¶”ë¡  ì‹¤í–‰
    print("ğŸ” ì¶”ë¡  ì‹¤í–‰ ì¤‘ (CPU ëª¨ë“œ)...")
    start_time = time.time()
    
    outputs = session.run(None, {input_name: img_batch})
    
    inference_time = time.time() - start_time
    
    print(f"   ì¶”ë¡  ì‹œê°„: {inference_time*1000:.1f}ms")
    print(f"   ì˜ˆìƒ FPS: {1/inference_time:.1f}")
    
    # í›„ì²˜ë¦¬ (NMS í¬í•¨)
    detections = postprocess_yolo_output_with_nms(outputs, conf_threshold=0.25, iou_threshold=0.45)
    
    print(f"   ê°ì§€ëœ ê°ì²´: {len(detections)}ê°œ")
    for i, det in enumerate(detections, 1):
        class_name = CLASS_NAMES[det['class_id']] if det['class_id'] < len(CLASS_NAMES) else f"class_{det['class_id']}"
        print(f"   {i}. {class_name}: ì‹ ë¢°ë„ {det['confidence']:.2f}")
    
    # ì‹œê°í™”
    output_path = OUTPUT_DIR / f"raspberry_pi_{image_path.stem}_prediction.png"
    draw_detections(str(image_path), detections, str(output_path), original_shape, input_size)
    
    print("\nâœ… ì™„ë£Œ!")
    print(f"   ê²°ê³¼ ì´ë¯¸ì§€: {output_path}")

if __name__ == "__main__":
    main()

