"""
ì•Œì•½ ì´ë¯¸ì§€ ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ
PNG ì´ë¯¸ì§€ë¥¼ COCO í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
"""

import os
import json
import shutil
import random
from pathlib import Path
from typing import List, Dict, Tuple
import cv2
import numpy as np
from PIL import Image
import yaml
from tqdm import tqdm


class PillDataProcessor:
    """ì•Œì•½ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "configs/data_config.yaml"):
        """ì´ˆê¸°í™”"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.data_config = self.config['data']
        self.source_path = Path(self.data_config['source_path'])
        self.processed_path = Path(self.data_config['processed_path'])
        self.classes = self.data_config['classes']
        self.image_size = self.data_config['image_size']
        
        # í´ë˜ìŠ¤ ID ë§¤í•‘ ìƒì„±
        self.class_to_id = {cls: idx for idx, cls in enumerate(self.classes)}
        self.id_to_class = {idx: cls for cls, idx in self.class_to_id.items()}
        
    def create_directory_structure(self):
        """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        dirs_to_create = [
            self.processed_path / "train" / "images",
            self.processed_path / "train" / "labels", 
            self.processed_path / "val" / "images",
            self.processed_path / "val" / "labels",
            self.processed_path / "test" / "images", 
            self.processed_path / "test" / "labels",
            self.processed_path / "annotations"
        ]
        
        for dir_path in dirs_to_create:
            dir_path.mkdir(parents=True, exist_ok=True)
            
        print(f"âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ: {self.processed_path}")
    
    def extract_pill_bbox(self, image_path: str) -> Tuple[int, int, int, int]:
        """
        ì•Œì•½ ì´ë¯¸ì§€ì—ì„œ ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
        ë‹¨ì¼ ì•Œì•½ì´ í¬í•¨ëœ ì´ë¯¸ì§€ì—ì„œ ì•Œì•½ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # ì„ê³„ê°’ ì²˜ë¦¬ (Otsu ë°©ë²•)
        _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
        
        # ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            # ì»¨íˆ¬ì–´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ì´ë¯¸ì§€ ì‚¬ìš©
            h, w = image.shape[:2]
            return 0, 0, w, h
        
        # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì„ íƒ (ì•Œì•½ìœ¼ë¡œ ê°€ì •)
        largest_contour = max(contours, key=cv2.contourArea)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        x, y, w, h = cv2.boundingRect(largest_contour)
        
        # ì•½ê°„ì˜ ì—¬ë°± ì¶”ê°€ (10%)
        margin_x = int(w * 0.1)
        margin_y = int(h * 0.1)
        
        x = max(0, x - margin_x)
        y = max(0, y - margin_y)
        w = min(image.shape[1] - x, w + 2 * margin_x)
        h = min(image.shape[0] - y, h + 2 * margin_y)
        
        return x, y, w, h
    
    def convert_to_yolo_format(self, bbox: Tuple[int, int, int, int], img_width: int, img_height: int) -> Tuple[float, float, float, float]:
        """
        ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì •ê·œí™”ëœ ì¤‘ì‹¬ì  ì¢Œí‘œì™€ í¬ê¸°)
        """
        x, y, w, h = bbox
        
        # ì¤‘ì‹¬ì  ê³„ì‚°
        center_x = x + w / 2
        center_y = y + h / 2
        
        # ì •ê·œí™”
        norm_center_x = center_x / img_width
        norm_center_y = center_y / img_height
        norm_width = w / img_width
        norm_height = h / img_height
        
        return norm_center_x, norm_center_y, norm_width, norm_height
    
    def process_single_class(self, class_name: str) -> List[Dict]:
        """ë‹¨ì¼ í´ë˜ìŠ¤ì˜ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬"""
        class_path = self.source_path / class_name
        if not class_path.exists():
            print(f"âš ï¸ í´ë˜ìŠ¤ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {class_path}")
            return []
        
        class_id = self.class_to_id[class_name]
        processed_images = []
        
        # PNG íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        image_files = list(class_path.glob("*.png"))
        print(f"ğŸ“ í´ë˜ìŠ¤ {class_name}: {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘...")
        
        for img_path in tqdm(image_files, desc=f"ì²˜ë¦¬ ì¤‘ - {class_name}"):
            try:
                # ì´ë¯¸ì§€ ë¡œë“œí•˜ì—¬ í¬ê¸° í™•ì¸
                with Image.open(img_path) as img:
                    img_width, img_height = img.size
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                bbox = self.extract_pill_bbox(img_path)
                
                # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                yolo_bbox = self.convert_to_yolo_format(bbox, img_width, img_height)
                
                processed_images.append({
                    'image_path': img_path,
                    'class_id': class_id,
                    'class_name': class_name,
                    'bbox': bbox,
                    'yolo_bbox': yolo_bbox,
                    'img_width': img_width,
                    'img_height': img_height
                })
                
            except Exception as e:
                print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ {img_path}: {e}")
                continue
        
        return processed_images
    
    def split_dataset(self, all_images: List[Dict]) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """ë°ì´í„°ì…‹ì„ train/val/testë¡œ ë¶„í• """
        random.shuffle(all_images)
        
        total_count = len(all_images)
        train_count = int(total_count * self.data_config['split_ratio']['train'])
        val_count = int(total_count * self.data_config['split_ratio']['val'])
        
        train_images = all_images[:train_count]
        val_images = all_images[train_count:train_count + val_count]
        test_images = all_images[train_count + val_count:]
        
        print(f"ğŸ“Š ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ:")
        print(f"   Train: {len(train_images)}ê°œ")
        print(f"   Val: {len(val_images)}ê°œ") 
        print(f"   Test: {len(test_images)}ê°œ")
        
        return train_images, val_images, test_images
    
    def save_dataset_split(self, images: List[Dict], split_name: str):
        """ë°ì´í„°ì…‹ ë¶„í•  ì €ì¥"""
        split_path = self.processed_path / split_name
        
        for idx, img_data in enumerate(tqdm(images, desc=f"{split_name} ì €ì¥ ì¤‘")):
            # ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±
            img_filename = f"{img_data['class_name']}_{idx:04d}.png"
            img_dest_path = split_path / "images" / img_filename
            
            # ì´ë¯¸ì§€ ë³µì‚¬
            shutil.copy2(img_data['image_path'], img_dest_path)
            
            # ë¼ë²¨ íŒŒì¼ ìƒì„± (YOLO í˜•ì‹)
            label_filename = f"{img_data['class_name']}_{idx:04d}.txt"
            label_dest_path = split_path / "labels" / label_filename
            
            with open(label_dest_path, 'w') as f:
                center_x, center_y, width, height = img_data['yolo_bbox']
                f.write(f"{img_data['class_id']} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n")
    
    def create_yolo_config(self):
        """YOLO í•™ìŠµìš© ì„¤ì • íŒŒì¼ ìƒì„±"""
        yolo_config = {
            'path': str(self.processed_path.absolute()),
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': len(self.classes),
            'names': self.classes
        }
        
        config_path = self.processed_path / "pill_dataset.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(yolo_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… YOLO ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
        return config_path
    
    def process_all_data(self):
        """ì „ì²´ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ ì•Œì•½ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
        self.create_directory_structure()
        
        # ëª¨ë“  í´ë˜ìŠ¤ ì²˜ë¦¬
        all_images = []
        for class_name in self.classes:
            class_images = self.process_single_class(class_name)
            all_images.extend(class_images)
        
        print(f"ğŸ“ˆ ì´ {len(all_images)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ë°ì´í„°ì…‹ ë¶„í• 
        train_images, val_images, test_images = self.split_dataset(all_images)
        
        # ë¶„í• ë³„ ì €ì¥
        self.save_dataset_split(train_images, "train")
        self.save_dataset_split(val_images, "val")
        self.save_dataset_split(test_images, "test")
        
        # YOLO ì„¤ì • íŒŒì¼ ìƒì„±
        yolo_config_path = self.create_yolo_config()
        
        print("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œ: {self.processed_path}")
        print(f"âš™ï¸ YOLO ì„¤ì • íŒŒì¼: {yolo_config_path}")
        
        return yolo_config_path


if __name__ == "__main__":
    # ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰
    processor = PillDataProcessor()
    processor.process_all_data()
