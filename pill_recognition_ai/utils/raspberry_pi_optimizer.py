"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ 4 Model Bìš© ëª¨ë¸ ìµœì í™” ë° ì¶”ë¡  ëª¨ë“ˆ
RTX 3060Tiì—ì„œ í•™ìŠµí•œ ëª¨ë¸ì„ ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ìµœì í™”í•©ë‹ˆë‹¤.
"""

import os
import time
import numpy as np
import cv2
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import yaml
import psutil
import subprocess
import platform


class RaspberryPiOptimizer:
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ 4 Model B ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "configs/raspberry_pi_config.yaml"):
        """ì´ˆê¸°í™”"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.pi_config = self.config['raspberry_pi']
        self.inference_config = self.config['inference']
        
        # ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ê°ì§€
        self.is_raspberry_pi = self._detect_raspberry_pi()
        
        if self.is_raspberry_pi:
            print("ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ê°ì§€ë¨")
            self._setup_raspberry_pi_environment()
        else:
            print("ğŸ’» ì¼ë°˜ PC í™˜ê²½ (ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™” ëª¨ë“œ)")
    
    def _detect_raspberry_pi(self) -> bool:
        """ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ê°ì§€"""
        try:
            # CPU ì •ë³´ í™•ì¸
            with open('/proc/cpuinfo', 'r') as f:
                cpuinfo = f.read()
                if 'BCM' in cpuinfo or 'Raspberry Pi' in cpuinfo:
                    return True
            
            # ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
            if 'arm' in platform.machine().lower():
                return True
                
        except:
            pass
        
        return False
    
    def _setup_raspberry_pi_environment(self):
        """ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ì„¤ì •"""
        if not self.is_raspberry_pi:
            return
        
        print("âš™ï¸ ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ì„¤ì • ì¤‘...")
        
        # CPU ì£¼íŒŒìˆ˜ ì„¤ì •
        try:
            subprocess.run(['sudo', 'cpufreq-set', '-g', 'ondemand'], 
                         check=True, capture_output=True)
            print("âœ… CPU ì£¼íŒŒìˆ˜ ì¡°ì ˆê¸° ì„¤ì • ì™„ë£Œ")
        except:
            print("âš ï¸ CPU ì£¼íŒŒìˆ˜ ì„¤ì • ì‹¤íŒ¨ (ê¶Œí•œ í•„ìš”)")
        
        # ë©”ëª¨ë¦¬ ì„¤ì • í™•ì¸
        self._check_memory_settings()
        
        # ì˜¨ë„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self._start_temperature_monitoring()
    
    def _check_memory_settings(self):
        """ë©”ëª¨ë¦¬ ì„¤ì • í™•ì¸"""
        try:
            # ìŠ¤ì™‘ ì„¤ì • í™•ì¸
            with open('/proc/swaps', 'r') as f:
                swaps = f.read()
                if 'swap' not in swaps.lower():
                    print("âš ï¸ ìŠ¤ì™‘ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥")
        except:
            pass
    
    def _start_temperature_monitoring(self):
        """ì˜¨ë„ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if not self.is_raspberry_pi:
            return
        
        try:
            # ì˜¨ë„ íŒŒì¼ ê²½ë¡œ í™•ì¸
            temp_files = [
                '/sys/class/thermal/thermal_zone0/temp',
                '/sys/class/hwmon/hwmon0/temp1_input'
            ]
            
            self.temp_file = None
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    self.temp_file = temp_file
                    break
            
            if self.temp_file:
                print(f"ğŸŒ¡ï¸ ì˜¨ë„ ëª¨ë‹ˆí„°ë§ í™œì„±í™”: {self.temp_file}")
            else:
                print("âš ï¸ ì˜¨ë„ ì„¼ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âš ï¸ ì˜¨ë„ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹¤íŒ¨: {e}")
    
    def get_system_info(self) -> Dict:
        """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜"""
        info = {
            'platform': platform.platform(),
            'architecture': platform.machine(),
            'cpu_count': psutil.cpu_count(),
            'memory_total': psutil.virtual_memory().total / 1024**3,  # GB
            'memory_available': psutil.virtual_memory().available / 1024**3,  # GB
            'is_raspberry_pi': self.is_raspberry_pi
        }
        
        if self.is_raspberry_pi and hasattr(self, 'temp_file') and self.temp_file:
            try:
                with open(self.temp_file, 'r') as f:
                    temp_millicelsius = int(f.read().strip())
                    info['temperature'] = temp_millicelsius / 1000  # ì„­ì”¨
            except:
                info['temperature'] = None
        
        return info
    
    def optimize_model_for_raspberry_pi(self, model_path: str) -> Dict:
        """ë¼ì¦ˆë² ë¦¬íŒŒì´ìš© ëª¨ë¸ ìµœì í™”"""
        print("ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ìš© ëª¨ë¸ ìµœì í™” ì‹œì‘...")
        
        try:
            from ultralytics import YOLO
            
            # ëª¨ë¸ ë¡œë“œ
            model = YOLO(model_path)
            
            # ìµœì í™” ì„¤ì •
            optimization_config = self.pi_config['model_optimization']
            
            exported_models = {}
            
            # ONNX ë³€í™˜ (ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ê°€ì¥ í˜¸í™˜ì„± ì¢‹ìŒ)
            if optimization_config.get('quantization', False):
                print("ğŸ”„ INT8 ì–‘ìí™” ONNX ë³€í™˜ ì¤‘...")
                try:
                    onnx_path = model.export(
                        format='onnx',
                        imgsz=self.config['data']['inference_image_size'],
                        int8=True,  # INT8 ì–‘ìí™”
                        dynamic=False,  # ì •ì  ë°°ì¹˜ í¬ê¸°
                        simplify=True,  # ëª¨ë¸ ë‹¨ìˆœí™”
                        opset=11  # ONNX opset ë²„ì „
                    )
                    exported_models['onnx_int8'] = onnx_path
                    print(f"âœ… INT8 ì–‘ìí™” ONNX ì €ì¥: {onnx_path}")
                except Exception as e:
                    print(f"âš ï¸ INT8 ì–‘ìí™” ì‹¤íŒ¨: {e}")
            
            # ì¼ë°˜ ONNX ë³€í™˜
            print("ğŸ”„ ì¼ë°˜ ONNX ë³€í™˜ ì¤‘...")
            onnx_path = model.export(
                format='onnx',
                imgsz=self.config['data']['inference_image_size'],
                dynamic=False,
                simplify=True,
                opset=11
            )
            exported_models['onnx'] = onnx_path
            print(f"âœ… ONNX ì €ì¥: {onnx_path}")
            
            # TensorFlow Lite ë³€í™˜ (ëª¨ë°”ì¼ ìµœì í™”)
            print("ğŸ”„ TensorFlow Lite ë³€í™˜ ì¤‘...")
            try:
                tflite_path = model.export(
                    format='tflite',
                    imgsz=self.config['data']['inference_image_size'],
                    int8=True,  # INT8 ì–‘ìí™”
                    dynamic=False
                )
                exported_models['tflite'] = tflite_path
                print(f"âœ… TensorFlow Lite ì €ì¥: {tflite_path}")
            except Exception as e:
                print(f"âš ï¸ TensorFlow Lite ë³€í™˜ ì‹¤íŒ¨: {e}")
            
            # ëª¨ë¸ í¬ê¸° ì •ë³´
            for format_name, model_path in exported_models.items():
                size_mb = os.path.getsize(model_path) / 1024**2
                print(f"ğŸ“Š {format_name} ëª¨ë¸ í¬ê¸°: {size_mb:.1f}MB")
            
            return exported_models
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {}
    
    def benchmark_model_performance(self, model_path: str, test_images: List[str]) -> Dict:
        """ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print("ğŸ“Š ë¼ì¦ˆë² ë¦¬íŒŒì´ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
        
        try:
            import onnxruntime as ort
            
            # ONNX Runtime ì„¸ì…˜ ìƒì„±
            providers = ['CPUExecutionProvider']  # ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œëŠ” CPUë§Œ ì‚¬ìš©
            
            session = ort.InferenceSession(model_path, providers=providers)
            
            # ì…ë ¥ í¬ê¸° í™•ì¸
            input_shape = session.get_inputs()[0].shape
            input_height, input_width = input_shape[2], input_shape[3]
            
            print(f"ğŸ“ ëª¨ë¸ ì…ë ¥ í¬ê¸°: {input_width}x{input_height}")
            
            # ì„±ëŠ¥ ì¸¡ì •
            inference_times = []
            memory_usage = []
            
            for i, img_path in enumerate(test_images[:10]):  # ìµœëŒ€ 10ê°œ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                img = cv2.imread(img_path)
                img_resized = cv2.resize(img, (input_width, input_height))
                img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
                img_normalized = img_rgb.astype(np.float32) / 255.0
                img_batch = np.expand_dims(img_normalized.transpose(2, 0, 1), axis=0)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì‹œì‘
                memory_before = psutil.virtual_memory().used / 1024**2  # MB
                
                # ì¶”ë¡  ì‹¤í–‰
                start_time = time.time()
                outputs = session.run(None, {session.get_inputs()[0].name: img_batch})
                inference_time = time.time() - start_time
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì¢…ë£Œ
                memory_after = psutil.virtual_memory().used / 1024**2  # MB
                
                inference_times.append(inference_time)
                memory_usage.append(memory_after - memory_before)
                
                print(f"   ì´ë¯¸ì§€ {i+1}: {inference_time*1000:.1f}ms, ë©”ëª¨ë¦¬: {memory_usage[-1]:.1f}MB")
            
            # í†µê³„ ê³„ì‚°
            avg_inference_time = np.mean(inference_times)
            avg_fps = 1.0 / avg_inference_time
            avg_memory = np.mean(memory_usage)
            
            benchmark_results = {
                'avg_inference_time_ms': avg_inference_time * 1000,
                'avg_fps': avg_fps,
                'avg_memory_usage_mb': avg_memory,
                'max_memory_usage_mb': np.max(memory_usage),
                'model_size_mb': os.path.getsize(model_path) / 1024**2,
                'input_size': f"{input_width}x{input_height}",
                'test_images': len(test_images)
            }
            
            print(f"\nğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
            print(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {benchmark_results['avg_inference_time_ms']:.1f}ms")
            print(f"   í‰ê·  FPS: {benchmark_results['avg_fps']:.1f}")
            print(f"   í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {benchmark_results['avg_memory_usage_mb']:.1f}MB")
            print(f"   ëª¨ë¸ í¬ê¸°: {benchmark_results['model_size_mb']:.1f}MB")
            
            # ëª©í‘œ ì„±ëŠ¥ê³¼ ë¹„êµ
            targets = self.pi_config['performance_targets']
            print(f"\nğŸ¯ ëª©í‘œ ì„±ëŠ¥ ë¹„êµ:")
            print(f"   FPS: {benchmark_results['avg_fps']:.1f} / {targets['fps']} (ëª©í‘œ)")
            print(f"   ì§€ì—°ì‹œê°„: {benchmark_results['avg_inference_time_ms']:.1f}ms / {targets['latency_ms']}ms (ëª©í‘œ)")
            print(f"   ë©”ëª¨ë¦¬: {benchmark_results['avg_memory_usage_mb']:.1f}MB / {targets['memory_usage_mb']}MB (ëª©í‘œ)")
            
            return benchmark_results
            
        except Exception as e:
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
            return {}
    
    def create_raspberry_pi_deployment_package(self, optimized_models: Dict, 
                                             config_path: str = "raspberry_pi_deployment") -> str:
        """ë¼ì¦ˆë² ë¦¬íŒŒì´ ë°°í¬ íŒ¨í‚¤ì§€ ìƒì„±"""
        print("ğŸ“¦ ë¼ì¦ˆë² ë¦¬íŒŒì´ ë°°í¬ íŒ¨í‚¤ì§€ ìƒì„± ì¤‘...")
        
        deployment_dir = Path(config_path)
        deployment_dir.mkdir(exist_ok=True)
        
        # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        inference_script = self._create_inference_script()
        script_path = deployment_dir / "pill_inference.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(inference_script)
        
        # ì„¤ì • íŒŒì¼ ë³µì‚¬
        config_file = deployment_dir / "config.yaml"
        with open(config_file, 'w', encoding='utf-8') as f:
            yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
        
        # ìµœì í™”ëœ ëª¨ë¸ë“¤ ë³µì‚¬
        models_dir = deployment_dir / "models"
        models_dir.mkdir(exist_ok=True)
        
        for format_name, model_path in optimized_models.items():
            dest_path = models_dir / f"pill_model.{format_name.split('_')[0]}"
            import shutil
            shutil.copy2(model_path, dest_path)
            print(f"âœ… ëª¨ë¸ ë³µì‚¬: {dest_path}")
        
        # requirements.txt ìƒì„±
        requirements = [
            "onnxruntime>=1.15.0",
            "opencv-python>=4.8.0",
            "numpy>=1.24.0",
            "pyyaml>=6.0",
            "psutil>=5.9.0"
        ]
        
        req_path = deployment_dir / "requirements.txt"
        with open(req_path, 'w') as f:
            f.write('\n'.join(requirements))
        
        # README ìƒì„±
        readme_content = self._create_deployment_readme()
        readme_path = deployment_dir / "README.md"
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print(f"âœ… ë°°í¬ íŒ¨í‚¤ì§€ ìƒì„± ì™„ë£Œ: {deployment_dir}")
        return str(deployment_dir)
    
    def _create_inference_script(self) -> str:
        """ë¼ì¦ˆë² ë¦¬íŒŒì´ìš© ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        return '''"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ 4 Model Bìš© ì•Œì•½ ì¸ì‹ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
"""

import cv2
import numpy as np
import yaml
import time
import psutil
from pathlib import Path
import onnxruntime as ort


class PillInference:
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ìš© ì•Œì•½ ì¸ì‹ ì¶”ë¡  í´ë˜ìŠ¤"""
    
    def __init__(self, config_path="config.yaml"):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.classes = self.config['data']['classes']
        self.confidence_threshold = self.config['inference']['postprocessing']['confidence_threshold']
        self.nms_threshold = self.config['inference']['postprocessing']['nms_threshold']
        
        # ëª¨ë¸ ë¡œë“œ
        self.model_path = "models/pill_model.onnx"
        self.session = ort.InferenceSession(self.model_path, providers=['CPUExecutionProvider'])
        
        # ì…ë ¥ í¬ê¸° í™•ì¸
        self.input_shape = self.session.get_inputs()[0].shape
        self.input_height, self.input_width = self.input_shape[2], self.input_shape[3]
        
        print(f"ğŸ“ ë¼ì¦ˆë² ë¦¬íŒŒì´ ì•Œì•½ ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“ ì…ë ¥ í¬ê¸°: {self.input_width}x{self.input_height}")
    
    def preprocess_image(self, image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # í¬ê¸° ì¡°ì •
        img_resized = cv2.resize(image, (self.input_width, self.input_height))
        
        # ìƒ‰ìƒ ë³€í™˜ ë° ì •ê·œí™”
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        img_normalized = img_rgb.astype(np.float32) / 255.0
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ ë° ì±„ë„ ìˆœì„œ ë³€ê²½
        img_batch = np.expand_dims(img_normalized.transpose(2, 0, 1), axis=0)
        
        return img_batch
    
    def postprocess_outputs(self, outputs, original_shape):
        """ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬"""
        # YOLO ì¶œë ¥ íŒŒì‹± (ê°„ë‹¨í•œ ë²„ì „)
        predictions = outputs[0][0]  # ì²« ë²ˆì§¸ ë°°ì¹˜
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ í•„í„°ë§
        confidences = predictions[:, 4]
        mask = confidences > self.confidence_threshold
        filtered_predictions = predictions[mask]
        
        if len(filtered_predictions) == 0:
            return []
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜
        boxes = []
        scores = []
        class_ids = []
        
        for pred in filtered_predictions:
            x_center, y_center, width, height = pred[:4]
            confidence = pred[4]
            class_scores = pred[5:]
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ í´ë˜ìŠ¤ ì„ íƒ
            class_id = np.argmax(class_scores)
            class_score = class_scores[class_id]
            
            # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            final_confidence = confidence * class_score
            
            if final_confidence > self.confidence_threshold:
                # ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                orig_h, orig_w = original_shape[:2]
                x1 = int((x_center - width/2) * orig_w)
                y1 = int((y_center - height/2) * orig_h)
                x2 = int((x_center + width/2) * orig_w)
                y2 = int((y_center + height/2) * orig_h)
                
                boxes.append([x1, y1, x2, y2])
                scores.append(final_confidence)
                class_ids.append(class_id)
        
        # NMS ì ìš©
        if len(boxes) > 0:
            boxes = np.array(boxes)
            scores = np.array(scores)
            class_ids = np.array(class_ids)
            
            indices = cv2.dnn.NMSBoxes(boxes.tolist(), scores.tolist(), 
                                      self.confidence_threshold, self.nms_threshold)
            
            if len(indices) > 0:
                indices = indices.flatten()
                return [(boxes[i], scores[i], class_ids[i]) for i in indices]
        
        return []
    
    def predict(self, image):
        """ì´ë¯¸ì§€ì—ì„œ ì•Œì•½ ì˜ˆì¸¡"""
        start_time = time.time()
        
        # ì „ì²˜ë¦¬
        input_tensor = self.preprocess_image(image)
        
        # ì¶”ë¡ 
        outputs = self.session.run(None, {self.session.get_inputs()[0].name: input_tensor})
        
        # í›„ì²˜ë¦¬
        detections = self.postprocess_outputs(outputs, image.shape)
        
        inference_time = time.time() - start_time
        
        # ê²°ê³¼ ì •ë¦¬
        results = []
        for box, score, class_id in detections:
            results.append({
                'bbox': box,
                'confidence': float(score),
                'class_id': int(class_id),
                'class_name': self.classes[class_id]
            })
        
        return results, inference_time
    
    def draw_results(self, image, results):
        """ê²°ê³¼ ì‹œê°í™”"""
        img_with_boxes = image.copy()
        
        for result in results:
            x1, y1, x2, y2 = result['bbox']
            confidence = result['confidence']
            class_name = result['class_name']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ë¼ë²¨ ê·¸ë¦¬ê¸°
            label = f"{class_name}: {confidence:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(img_with_boxes, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), (0, 255, 0), -1)
            cv2.putText(img_with_boxes, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        return img_with_boxes


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    inference_system = PillInference()
    
    # ì¹´ë©”ë¼ ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸
    cap = cv2.VideoCapture(0)  # ì›¹ìº  ì‚¬ìš©
    
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ íŒŒì¼ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        # ì´ë¯¸ì§€ íŒŒì¼ í…ŒìŠ¤íŠ¸
        test_image_path = "test_image.jpg"
        if Path(test_image_path).exists():
            image = cv2.imread(test_image_path)
            results, inference_time = inference_system.predict(image)
            
            print(f"ğŸ” ê°ì§€ëœ ì•Œì•½: {len(results)}ê°œ")
            print(f"â±ï¸ ì¶”ë¡  ì‹œê°„: {inference_time*1000:.1f}ms")
            
            for i, result in enumerate(results):
                print(f"   {i+1}. {result['class_name']} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
            
            # ê²°ê³¼ ì‹œê°í™”
            img_with_results = inference_system.draw_results(image, results)
            cv2.imwrite("result.jpg", img_with_results)
            print("âœ… ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: result.jpg")
        else:
            print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸ“¹ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘ (ESC í‚¤ë¡œ ì¢…ë£Œ)")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # ì¶”ë¡  ì‹¤í–‰
        results, inference_time = inference_system.predict(frame)
        
        # ê²°ê³¼ ì‹œê°í™”
        frame_with_results = inference_system.draw_results(frame, results)
        
        # ì •ë³´ í‘œì‹œ
        info_text = f"FPS: {1/inference_time:.1f} | Pills: {len(results)}"
        cv2.putText(frame_with_results, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # í™”ë©´ ì¶œë ¥
        cv2.imshow('Pill Recognition', frame_with_results)
        
        # ESC í‚¤ë¡œ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == 27:
            break
    
    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
'''
    
    def _create_deployment_readme(self) -> str:
        """ë°°í¬ìš© README ìƒì„±"""
        return '''# ë¼ì¦ˆë² ë¦¬íŒŒì´ 4 Model B ì•Œì•½ ì¸ì‹ ì‹œìŠ¤í…œ

## ì„¤ì¹˜ ë°©ë²•

### 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
```bash
sudo apt update && sudo apt upgrade -y
```

### 2. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

### 3. ì‹¤í–‰
```bash
python pill_inference.py
```

## ì„±ëŠ¥ ëª©í‘œ
- FPS: 5 FPS ì´ìƒ
- ì§€ì—°ì‹œê°„: 200ms ì´í•˜
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 512MB ì´í•˜

## ë¬¸ì œ í•´ê²°
- ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ: ìŠ¤ì™‘ í™œì„±í™”
- ì˜¨ë„ ê³¼ì—´ ì‹œ: ì¿¨ë§ íŒ¬ ì„¤ì¹˜
- ì„±ëŠ¥ ì €í•˜ ì‹œ: CPU ì£¼íŒŒìˆ˜ í™•ì¸

## í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- ë¼ì¦ˆë² ë¦¬íŒŒì´ 4 Model B (4GB RAM ê¶Œì¥)
- MicroSD ì¹´ë“œ (32GB ì´ìƒ)
- ì›¹ìº  ë˜ëŠ” ì¹´ë©”ë¼ ëª¨ë“ˆ
'''


if __name__ == "__main__":
    # ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™” í…ŒìŠ¤íŠ¸
    optimizer = RaspberryPiOptimizer()
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    system_info = optimizer.get_system_info()
    print("ğŸ“ ì‹œìŠ¤í…œ ì •ë³´:")
    for key, value in system_info.items():
        print(f"   {key}: {value}")
    
    # ëª¨ë¸ ìµœì í™” (ì˜ˆì‹œ)
    # model_path = "results/training_20241027_085100/best_model.pt"
    # optimized_models = optimizer.optimize_model_for_raspberry_pi(model_path)
    
    # ë°°í¬ íŒ¨í‚¤ì§€ ìƒì„±
    # deployment_dir = optimizer.create_raspberry_pi_deployment_package(optimized_models)
