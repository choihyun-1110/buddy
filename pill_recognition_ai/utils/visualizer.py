"""
ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ ê²°ê³¼ ì‹œê°í™” ëª¨ë“ˆ
ë°”ìš´ë”© ë°•ìŠ¤, ì˜ˆì¸¡ ê²°ê³¼ ë“±ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from pathlib import Path
from typing import List, Tuple, Dict
import random
from PIL import Image, ImageDraw, ImageFont
import yaml


class ResultVisualizer:
    """ê²°ê³¼ ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "configs/data_config.yaml"):
        """ì´ˆê¸°í™”"""
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        self.classes = self.config['data']['classes']
        self.class_colors = self._generate_colors(len(self.classes))
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        self.output_dir = Path("results/visualizations")
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def _generate_colors(self, num_classes: int) -> List[Tuple[int, int, int]]:
        """í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ìƒì„±"""
        colors = []
        for i in range(num_classes):
            # HSV ìƒ‰ìƒ ê³µê°„ì—ì„œ ê· ë“±í•˜ê²Œ ë¶„í¬ (0-179 ë²”ìœ„ë¡œ ì œí•œ)
            hue = int(179 * i / num_classes)
            hsv = np.array([[[hue, 255, 255]]], dtype=np.uint8)
            rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)[0][0]
            colors.append(tuple(rgb))
        return colors
    
    def visualize_bounding_boxes(self, image_path: str, bbox_data: List[Dict], 
                                output_path: str = None, title: str = "Bounding Box Visualization"):
        """ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™”"""
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return
        
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        height, width = image_rgb.shape[:2]
        
        # matplotlibìœ¼ë¡œ ì‹œê°í™”
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        ax.imshow(image_rgb)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for bbox_info in bbox_data:
            class_id = bbox_info['class_id']
            class_name = self.classes[class_id]
            color = self.class_colors[class_id]
            
            # YOLO í˜•ì‹ì„ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
            center_x, center_y, bbox_w, bbox_h = bbox_info['bbox']
            x = (center_x - bbox_w / 2) * width
            y = (center_y - bbox_h / 2) * height
            w = bbox_w * width
            h = bbox_h * height
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            rect = patches.Rectangle((x, y), w, h, linewidth=2, 
                                   edgecolor=[c/255 for c in color], 
                                   facecolor='none')
            ax.add_patch(rect)
            
            # í´ë˜ìŠ¤ ë¼ë²¨ ì¶”ê°€
            ax.text(x, y-5, f"{class_name}", fontsize=10, 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor=[c/255 for c in color], alpha=0.7),
                   color='white', weight='bold')
        
        ax.set_title(title, fontsize=14, weight='bold')
        ax.axis('off')
        
        # ê²°ê³¼ ì €ì¥
        if output_path is None:
            output_path = self.output_dir / f"bbox_visualization_{Path(image_path).stem}.png"
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™” ì €ì¥: {output_path}")
        return output_path
    
    def visualize_data_preprocessing_results(self, dataset_path: str = "dataset"):
        """ë°ì´í„° ì „ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™”"""
        print("ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        dataset_path = Path(dataset_path)
        splits = ['train', 'val', 'test']
        
        for split in splits:
            images_dir = dataset_path / split / 'images'
            labels_dir = dataset_path / split / 'labels'
            
            if not images_dir.exists():
                print(f"âš ï¸ {split} ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_dir}")
                continue
            
            # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ ì„ íƒ
            image_files = list(images_dir.glob('*.png'))[:5]  # ìµœëŒ€ 5ê°œ
            
            for i, img_file in enumerate(image_files):
                label_file = labels_dir / f"{img_file.stem}.txt"
                
                if not label_file.exists():
                    continue
                
                # ë¼ë²¨ ë°ì´í„° ì½ê¸°
                bbox_data = []
                with open(label_file, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            bbox = [float(x) for x in parts[1:5]]
                            bbox_data.append({
                                'class_id': class_id,
                                'bbox': bbox
                            })
                
                # ì‹œê°í™”
                output_path = self.output_dir / f"{split}_sample_{i+1}.png"
                self.visualize_bounding_boxes(
                    str(img_file), 
                    bbox_data, 
                    str(output_path),
                    f"{split.upper()} Sample {i+1} - {len(bbox_data)} pills detected"
                )
        
        print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì‹œê°í™” ì™„ë£Œ: {self.output_dir}")
    
    def visualize_augmentation_results(self, original_dataset: str = "dataset", 
                                     augmented_dataset: str = "dataset_augmented"):
        """ë°ì´í„° ì¦ê°• ê²°ê³¼ ì‹œê°í™”"""
        print("ğŸ”„ ë°ì´í„° ì¦ê°• ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        original_path = Path(original_dataset)
        augmented_path = Path(augmented_dataset)
        
        if not augmented_path.exists():
            print(f"âš ï¸ ì¦ê°•ëœ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {augmented_path}")
            return
        
        # ì›ë³¸ê³¼ ì¦ê°•ëœ ì´ë¯¸ì§€ ë¹„êµ
        splits = ['train', 'val', 'test']
        
        for split in splits:
            orig_images = list((original_path / split / 'images').glob('*.png'))[:3]
            aug_images = list((augmented_path / split / 'images').glob('*.png'))[:3]
            
            # ì›ë³¸ ì´ë¯¸ì§€ë“¤ ì‹œê°í™”
            for i, img_file in enumerate(orig_images):
                label_file = original_path / split / 'labels' / f"{img_file.stem}.txt"
                
                if label_file.exists():
                    bbox_data = self._read_label_file(label_file)
                    output_path = self.output_dir / f"original_{split}_{i+1}.png"
                    self.visualize_bounding_boxes(
                        str(img_file), 
                        bbox_data, 
                        str(output_path),
                        f"Original {split.upper()} Sample {i+1}"
                    )
            
            # ì¦ê°•ëœ ì´ë¯¸ì§€ë“¤ ì‹œê°í™”
            for i, img_file in enumerate(aug_images):
                label_file = augmented_path / split / 'labels' / f"{img_file.stem}.txt"
                
                if label_file.exists():
                    bbox_data = self._read_label_file(label_file)
                    output_path = self.output_dir / f"augmented_{split}_{i+1}.png"
                    self.visualize_bounding_boxes(
                        str(img_file), 
                        bbox_data, 
                        str(output_path),
                        f"Augmented {split.upper()} Sample {i+1}"
                    )
        
        print(f"âœ… ë°ì´í„° ì¦ê°• ì‹œê°í™” ì™„ë£Œ: {self.output_dir}")
    
    def _read_label_file(self, label_file: Path) -> List[Dict]:
        """ë¼ë²¨ íŒŒì¼ ì½ê¸°"""
        bbox_data = []
        with open(label_file, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    bbox = [float(x) for x in parts[1:5]]
                    bbox_data.append({
                        'class_id': class_id,
                        'bbox': bbox
                    })
        return bbox_data
    
    def visualize_model_predictions(self, model_path: str, test_images_dir: str, 
                                   num_samples: int = 5):
        """ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”"""
        print("ğŸ” ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        try:
            from ultralytics import YOLO
            
            # ëª¨ë¸ ë¡œë“œ
            model = YOLO(model_path)
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤ ì„ íƒ
            test_images = list(Path(test_images_dir).glob('*.png'))[:num_samples]
            
            for i, img_path in enumerate(test_images):
                # ì˜ˆì¸¡ ì‹¤í–‰
                results = model(str(img_path))
                
                # ê²°ê³¼ ì‹œê°í™”
                result_img = results[0].plot()
                
                # ì €ì¥
                output_path = self.output_dir / f"prediction_sample_{i+1}.png"
                cv2.imwrite(str(output_path), result_img)
                
                print(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {output_path}")
            
            print(f"âœ… ëª¨ë¸ ì˜ˆì¸¡ ì‹œê°í™” ì™„ë£Œ: {self.output_dir}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì˜ˆì¸¡ ì‹œê°í™” ì‹¤íŒ¨: {e}")
    
    def create_summary_visualization(self):
        """ì „ì²´ ê²°ê³¼ ìš”ì•½ ì‹œê°í™”"""
        print("ğŸ“ˆ ì „ì²´ ê²°ê³¼ ìš”ì•½ ì‹œê°í™” ì¤‘...")
        
        # ìƒì„±ëœ ì´ë¯¸ì§€ë“¤ ìˆ˜ì§‘
        vis_files = list(self.output_dir.glob('*.png'))
        
        if not vis_files:
            print("âš ï¸ ì‹œê°í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê·¸ë¦¬ë“œ í˜•íƒœë¡œ ìš”ì•½ ì´ë¯¸ì§€ ìƒì„±
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        for i, img_file in enumerate(vis_files[:6]):  # ìµœëŒ€ 6ê°œ
            img = cv2.imread(str(img_file))
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            axes[i].imshow(img_rgb)
            axes[i].set_title(img_file.stem, fontsize=10)
            axes[i].axis('off')
        
        # ë¹ˆ ì¶• ìˆ¨ê¸°ê¸°
        for i in range(len(vis_files), 6):
            axes[i].axis('off')
        
        plt.suptitle('ì•Œì•½ ì¸ì‹ AI ëª¨ë¸ ê°œë°œ ê²°ê³¼ ì‹œê°í™”', fontsize=16, weight='bold')
        plt.tight_layout()
        
        summary_path = self.output_dir / "summary_visualization.png"
        plt.savefig(summary_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… ìš”ì•½ ì‹œê°í™” ì €ì¥: {summary_path}")
        return summary_path
    
    def visualize_class_distribution(self, dataset_path: str = "dataset"):
        """í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”"""
        print("ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” ì¤‘...")
        
        dataset_path = Path(dataset_path)
        class_counts = {cls: 0 for cls in self.classes}
        
        # ëª¨ë“  ë¼ë²¨ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì¹´ìš´íŠ¸
        for split in ['train', 'val', 'test']:
            labels_dir = dataset_path / split / 'labels'
            if labels_dir.exists():
                for label_file in labels_dir.glob('*.txt'):
                    with open(label_file, 'r') as f:
                        for line in f:
                            parts = line.strip().split()
                            if len(parts) >= 5:
                                class_id = int(parts[0])
                                if class_id < len(self.classes):
                                    class_counts[self.classes[class_id]] += 1
        
        # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±
        fig, ax = plt.subplots(figsize=(15, 8))
        
        classes = list(class_counts.keys())
        counts = list(class_counts.values())
        colors = [self.class_colors[i] for i in range(len(classes))]
        
        bars = ax.bar(range(len(classes)), counts, color=[c/255 for c in colors])
        
        # ê°’ í‘œì‹œ
        for bar, count in zip(bars, counts):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                   str(count), ha='center', va='bottom')
        
        ax.set_xlabel('Pill Classes', fontsize=12)
        ax.set_ylabel('Number of Images', fontsize=12)
        ax.set_title('Class Distribution in Dataset', fontsize=14, weight='bold')
        ax.set_xticks(range(len(classes)))
        ax.set_xticklabels(classes, rotation=45, ha='right')
        
        plt.tight_layout()
        
        dist_path = self.output_dir / "class_distribution.png"
        plt.savefig(dist_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™” ì €ì¥: {dist_path}")
        return dist_path


if __name__ == "__main__":
    # ì‹œê°í™” ì‹¤í–‰
    visualizer = ResultVisualizer()
    
    # ë°ì´í„° ì „ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™”
    visualizer.visualize_data_preprocessing_results()
    
    # í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”
    visualizer.visualize_class_distribution()
    
    # ìš”ì•½ ì‹œê°í™”
    visualizer.create_summary_visualization()
