"""
ë¼ì¦ˆë² ë¦¬íŒŒì´ ë°°í¬ ì „ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
PCì—ì„œ CPU ëª¨ë“œë¡œ ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""
import time
import numpy as np
import cv2
from pathlib import Path
import onnxruntime as ort
from typing import List, Tuple, Dict
import psutil


class RaspberryPiSimulator:
    """ë¼ì¦ˆë² ë¦¬íŒŒì´ í™˜ê²½ ì‹œë®¬ë ˆì´í„°"""
    
    def __init__(self, onnx_model_path: str):
        """ì´ˆê¸°í™”"""
        self.onnx_model_path = Path(onnx_model_path)
        
        if not self.onnx_model_path.exists():
            raise FileNotFoundError(f"ONNX ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {onnx_model_path}")
        
        # ONNX Runtime ì„¸ì…˜ ìƒì„± (CPU ì „ìš©)
        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        
        # ë¼ì¦ˆë² ë¦¬íŒŒì´ëŠ” GPUê°€ ì—†ìœ¼ë¯€ë¡œ CPUë§Œ ì‚¬ìš©
        providers = ['CPUExecutionProvider']
        
        self.session = ort.InferenceSession(
            str(self.onnx_model_path),
            sess_options=sess_options,
            providers=providers
        )
        
        # ì…ë ¥/ì¶œë ¥ ì •ë³´
        self.input_name = self.session.get_inputs()[0].name
        self.output_names = [output.name for output in self.session.get_outputs()]
        
        # ì…ë ¥ í¬ê¸° í™•ì¸
        input_shape = self.session.get_inputs()[0].shape
        self.input_size = (input_shape[2], input_shape[3])  # (width, height)
        
        print(f"âœ… ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.onnx_model_path.name}")
        print(f"   ì…ë ¥ í¬ê¸°: {self.input_size}")
        print(f"   ì‹¤í–‰ ê³µê¸‰ì: {providers}")
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        img = cv2.imread(str(image_path))
        if img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        # ì›ë³¸ í¬ê¸° ì €ì¥
        original_shape = img.shape[:2]
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        img_resized = cv2.resize(img, self.input_size, interpolation=cv2.INTER_LINEAR)
        
        # BGR -> RGB
        img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        
        # ì •ê·œí™” (0-255 -> 0-1)
        img_normalized = img_rgb.astype(np.float32) / 255.0
        
        # (H, W, C) -> (C, H, W)
        img_transposed = img_normalized.transpose(2, 0, 1)
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, C, H, W)
        img_batch = np.expand_dims(img_transposed, axis=0)
        
        return img_batch, original_shape
    
    def postprocess_output(self, outputs: List[np.ndarray], conf_threshold: float = 0.25) -> List[Dict]:
        """YOLO ì¶œë ¥ í›„ì²˜ë¦¬"""
        # YOLO ONNX ì¶œë ¥ì€ ì¼ë°˜ì ìœ¼ë¡œ [batch, num_detections, 6] í˜•íƒœ
        # [x_center, y_center, width, height, confidence, class_id]
        
        detections = []
        
        if len(outputs) > 0:
            output = outputs[0]  # ì²« ë²ˆì§¸ ì¶œë ¥
            if output.ndim == 3:
                output = output[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°
            
            # ì‹ ë¢°ë„ ì„ê³„ê°’ í•„í„°ë§
            confidences = output[:, 4]
            valid_indices = confidences > conf_threshold
            
            if np.any(valid_indices):
                valid_outputs = output[valid_indices]
                
                for det in valid_outputs:
                    x_center, y_center, width, height, conf, class_id = det[:6]
                    
                    detections.append({
                        'bbox': [x_center, y_center, width, height],
                        'confidence': float(conf),
                        'class_id': int(class_id)
                    })
        
        return detections
    
    def predict(self, image_path: str, conf_threshold: float = 0.25) -> Tuple[List[Dict], float]:
        """ì¶”ë¡  ì‹¤í–‰ ë° ì„±ëŠ¥ ì¸¡ì •"""
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_batch, original_shape = self.preprocess_image(image_path)
        
        # CPU ì‚¬ìš©ë¥  ì¸¡ì • ì‹œì‘
        cpu_percent_start = psutil.cpu_percent(interval=0.1)
        
        # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        
        # ONNX Runtime ì¶”ë¡ 
        outputs = self.session.run(self.output_names, {self.input_name: img_batch})
        
        # ì¶”ë¡  ì™„ë£Œ
        inference_time = time.time() - start_time
        
        # CPU ì‚¬ìš©ë¥  ì¸¡ì •
        cpu_percent_end = psutil.cpu_percent(interval=0.1)
        cpu_usage = max(cpu_percent_start, cpu_percent_end)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        memory_info = psutil.virtual_memory()
        memory_used_mb = memory_info.used / (1024 ** 2)
        
        # í›„ì²˜ë¦¬
        detections = self.postprocess_output(outputs, conf_threshold)
        
        return detections, inference_time, cpu_usage, memory_used_mb
    
    def test_inference(self, image_paths: List[str], num_runs: int = 5):
        """ì¶”ë¡  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\n" + "="*60)
        print("ğŸ§ª ë¼ì¦ˆë² ë¦¬íŒŒì´ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*60)
        
        all_times = []
        all_cpu_usage = []
        all_memory_usage = []
        
        for img_path in image_paths:
            img_path = Path(img_path)
            if not img_path.exists():
                print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
                continue
            
            print(f"\nğŸ“¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {img_path.name}")
            
            times = []
            cpu_usages = []
            memory_usages = []
            
            # ì›Œë°ì—… (ì²« ì‹¤í–‰ì€ ëŠë¦´ ìˆ˜ ìˆìŒ)
            print("   ì›Œë°ì—… ì¤‘...")
            self.predict(str(img_path))
            
            # ì‹¤ì œ ì¸¡ì •
            print(f"   {num_runs}íšŒ ì¶”ë¡  ì‹¤í–‰ ì¤‘...")
            for i in range(num_runs):
                detections, inference_time, cpu_usage, memory_used = self.predict(str(img_path))
                times.append(inference_time)
                cpu_usages.append(cpu_usage)
                memory_usages.append(memory_used)
                
                if i == 0:
                    print(f"   ì²« ë²ˆì§¸ ì¶”ë¡ : {inference_time*1000:.1f}ms, ê°ì§€ëœ ê°ì²´: {len(detections)}ê°œ")
            
            avg_time = np.mean(times[1:])  # ì²« ë²ˆì§¸ ì œì™¸í•œ í‰ê· 
            min_time = np.min(times[1:])
            max_time = np.max(times[1:])
            avg_cpu = np.mean(cpu_usages[1:])
            avg_memory = np.mean(memory_usages[1:])
            
            print(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time*1000:.1f}ms (ìµœì†Œ: {min_time*1000:.1f}ms, ìµœëŒ€: {max_time*1000:.1f}ms)")
            print(f"   í‰ê·  CPU ì‚¬ìš©ë¥ : {avg_cpu:.1f}%")
            print(f"   í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {avg_memory:.1f}MB")
            print(f"   ì˜ˆìƒ FPS: {1/avg_time:.1f}")
            
            all_times.extend(times[1:])
            all_cpu_usage.extend(cpu_usages[1:])
            all_memory_usage.extend(memory_usages[1:])
        
        # ì „ì²´ í†µê³„
        print("\n" + "="*60)
        print("ğŸ“Š ì „ì²´ ì„±ëŠ¥ í†µê³„")
        print("="*60)
        print(f"ì „ì²´ í‰ê·  ì¶”ë¡  ì‹œê°„: {np.mean(all_times)*1000:.1f}ms")
        print(f"ì „ì²´ í‰ê·  CPU ì‚¬ìš©ë¥ : {np.mean(all_cpu_usage):.1f}%")
        print(f"ì „ì²´ í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {np.mean(all_memory_usage):.1f}MB")
        print(f"ì „ì²´ í‰ê·  FPS: {1/np.mean(all_times):.1f}")
        
        # ë¼ì¦ˆë² ë¦¬íŒŒì´ ì„±ëŠ¥ í‰ê°€
        print("\n" + "="*60)
        print("ğŸ¯ ë¼ì¦ˆë² ë¦¬íŒŒì´ í˜¸í™˜ì„± í‰ê°€")
        print("="*60)
        
        avg_time_ms = np.mean(all_times) * 1000
        avg_fps = 1 / np.mean(all_times)
        
        if avg_time_ms < 100:
            print("âœ… ë§¤ìš° ë¹ ë¦„: ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (ëª©í‘œ: 15 FPS ì´ìƒ)")
        elif avg_time_ms < 200:
            print("âœ… ë¹ ë¦„: ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥ (ëª©í‘œ: 5-15 FPS)")
        elif avg_time_ms < 500:
            print("âš ï¸ ë³´í†µ: ì‹¤ì‹œê°„ ì²˜ë¦¬ëŠ” ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ (ëª©í‘œ: 2-5 FPS)")
        else:
            print("âŒ ëŠë¦¼: ì‹¤ì‹œê°„ ì²˜ë¦¬ ì–´ë ¤ì›€ (ëª©í‘œ: 2 FPS ë¯¸ë§Œ)")
        
        print(f"\nê¶Œì¥ ì‚¬í•­:")
        if avg_time_ms > 200:
            print("   - ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš” (640 -> 416)")
            print("   - ì…ë ¥ ì „ì²˜ë¦¬ë¥¼ ìµœì í™”í•˜ì„¸ìš”")
            print("   - ONNX ëª¨ë¸ì„ ë” ë‹¨ìˆœí™”í•˜ì„¸ìš”")
        else:
            print("   - í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ë¼ì¦ˆë² ë¦¬íŒŒì´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        return {
            'avg_inference_time_ms': avg_time_ms,
            'avg_fps': avg_fps,
            'avg_cpu_usage': np.mean(all_cpu_usage),
            'avg_memory_mb': np.mean(all_memory_usage)
        }


def export_to_onnx(model_path: str, output_path: str = None):
    """ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜"""
    from ultralytics import YOLO
    
    print(f"ğŸ“¤ ONNX ë³€í™˜ ì‹œì‘: {model_path}")
    
    model = YOLO(model_path)
    
    if output_path is None:
        output_path = model_path.replace('.pt', '.onnx')
    
    # ONNX ë³€í™˜ (ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™”)
    exported_path = model.export(
        format='onnx',
        imgsz=640,
        dynamic=False,  # ì •ì  í¬ê¸° (ë” ë¹ ë¦„)
        simplify=True,  # ëª¨ë¸ ë‹¨ìˆœí™”
        opset=12  # ONNX opset ë²„ì „ (í˜¸í™˜ì„±)
    )
    
    print(f"âœ… ONNX ë³€í™˜ ì™„ë£Œ: {exported_path}")
    return exported_path


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ë¼ì¦ˆë² ë¦¬íŒŒì´ ë°°í¬ ì „ í…ŒìŠ¤íŠ¸")
    parser.add_argument("--model", default="results/training_20251031_201041/best_model.pt",
                       help="í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (.pt ë˜ëŠ” .onnx)")
    parser.add_argument("--images", nargs="+", 
                       default=["../real_image0.jpeg", "../real_image1.jpeg"],
                       help="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ")
    parser.add_argument("--export", action="store_true",
                       help="ë¨¼ì € ONNXë¡œ ë³€í™˜")
    parser.add_argument("--runs", type=int, default=5,
                       help="ê° ì´ë¯¸ì§€ë‹¹ ì¶”ë¡  ì‹¤í–‰ íšŸìˆ˜")
    
    args = parser.parse_args()
    
    model_path = Path(args.model)
    
    # ONNX ë³€í™˜
    if args.export or not model_path.suffix == '.onnx':
        if model_path.suffix == '.pt':
            print("ğŸ”„ .pt íŒŒì¼ì„ ONNXë¡œ ë³€í™˜í•©ë‹ˆë‹¤...")
            onnx_path = export_to_onnx(str(model_path))
        else:
            onnx_path = str(model_path)
    else:
        onnx_path = str(model_path)
    
    # ë¼ì¦ˆë² ë¦¬íŒŒì´ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
    simulator = RaspberryPiSimulator(onnx_path)
    results = simulator.test_inference(args.images, num_runs=args.runs)
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

